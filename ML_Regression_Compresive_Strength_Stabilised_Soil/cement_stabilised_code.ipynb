{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2790019,"sourceType":"datasetVersion","datasetId":1703773}],"dockerImageVersionId":30145,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt  \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n\nfrom sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datas = pd.read_csv('../input/cementdatasetnew/CementDataSet - Copy.csv')\ndatas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datas.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datas.size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datas.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datas.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datas.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datas.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datas.isnull().sum()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n# Creating Bar chart as the Target variable is Continuous\ndatas['UCS_std_Soaked_7Days'].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n# Creating Bar chart as the Target variable is Continuous\ndatas['UCS_std_Soaked_28Days'].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting histograms of multiple columns together\ndatas.hist(['Organic.Content', 'Sand', 'Silt',\n                'Clay', 'Clay2','Gravel', \n                           'Cement'], figsize=(18,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=[17,8])\n\n#ploting correlation plot\n\nsb.heatmap(datas.corr(),annot=True, cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating correlation matrix\nContinuousCols=['Organic.Content', 'Sand', 'Silt','Clay', 'Clay2','Gravel','Cement','UCS_std_Soaked_7Days','UCS_std_Soaked_28Days']\n\n# Creating the correlation matrix\nCorrelationData=datas[ContinuousCols].corr()\nCorrelationData","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ContinuousCols=['Organic.Content','Sand','Silt','Clay','Clay2','Gravel','Cement']\n\n# Plotting scatter chart for each predictor vs the target variable\nfor predictor in ContinuousCols:\n    datas.plot.scatter(x=predictor, y='UCS_std_Soaked_7Days', figsize=(5,3), title=predictor+\" VS \"+ 'UCS_std_Soaked_7Days')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ContinuousCols=['Organic.Content','Sand','Silt','Clay','Clay2','Gravel','Cement']\n\n# Plotting scatter chart for each predictor vs the target variable\nfor predictor in ContinuousCols:\n    datas.plot.scatter(x=predictor, y='UCS_std_Soaked_28Days', figsize=(5,3), title=predictor+\" VS \"+ 'UCS_std_Soaked_28Days')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    datas.plot.scatter(x='UCS_std_Soaked_7Days', y='UCS_std_Soaked_28Days', figsize=(5,3), title='UCS_std_Soaked_7Days'+\" VS \"+ 'UCS_std_Soaked_28Days')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SelectedColumns=['Organic.Content','Sand','Silt','Clay','Clay2','Gravel','Cement']\n\n# Selecting final columns\nDataForML=datas[SelectedColumns]\nDataForML","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Treating all the nominal variables at once using dummy variables\nDataForML_Numeric=pd.get_dummies(DataForML)\n\n# Adding Target Variable to the data\nDataForML_Numeric['UCS_std_Soaked_7Days']=datas['UCS_std_Soaked_7Days']\n# Adding Target Variable to the data\nDataForML_Numeric['UCS_std_Soaked_28Days']=datas['UCS_std_Soaked_28Days']\n\n# Printing sample rows\nDataForML_Numeric.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing all the column names for our reference\nDataForML_Numeric.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate Target Variable and Predictor Variables\nTargetVariable='UCS_std_Soaked_7Days'\nPredictors=['Organic.Content','Sand','Silt','Clay','Clay2','Gravel','Cement']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split dataset into training and testing\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    \"                     Linear Regression\": LinearRegression(),\n    \"                 L2 (Ridge) Regression\": Ridge(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n    \"                         Decision Tree\": DecisionTreeRegressor(),\n    \"                        Neural Network\": MLPRegressor(),\n    \"                         Random Forest\": RandomForestRegressor(),\n    \"                     Gradient Boosting\": GradientBoostingRegressor(),\n    \"                              AdaBoost\": AdaBoostRegressor()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, model in models.items():\n    print(name + \" R^2: {:.5f}\".format(model.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = Ridge()\nbest_model.fit(X_train, y_train)\n\nprint(\"Model R^2 (Before Optimization): {:.5f}\".format(best_model.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_predict = list(best_model.predict(X_test))\npredicted_df = {'predicted_values': x_predict, 'original_values': y_test}\n#creating new dataframe\npd.DataFrame(predicted_df).head(53)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate Target Variable and Predictor Variables\nTargetVariable='UCS_std_Soaked_28Days'\nPredictors=['Organic.Content','Sand','Silt','Clay','Clay2','Gravel','Cement']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sanity check for the sampled data\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    \"                     Linear Regression\": LinearRegression(),\n    \"                 L2 (Ridge) Regression\": Ridge(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n    \"                         Decision Tree\": DecisionTreeRegressor(),\n    \"                        Neural Network\": MLPRegressor(),\n    \"                         Random Forest\": RandomForestRegressor(),\n    \"                     Gradient Boosting\": GradientBoostingRegressor(),\n    \"                              AdaBoost\": AdaBoostRegressor()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, model in models.items():\n    print(name + \" R^2: {:.5f}\".format(model.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = Ridge()\nbest_model.fit(X_train, y_train)\n\nprint(\"Model R^2 (Before Optimization): {:.5f}\".format(best_model.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_predict = list(best_model.predict(X_test))\npredicted_df = {'predicted_values': x_predict, 'original_values': y_test}\n#creating new dataframe\npd.DataFrame(predicted_df).head(53)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}